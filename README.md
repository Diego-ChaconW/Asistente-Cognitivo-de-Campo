# ğŸ¥ Azure RAG Chat - Chat con Manuales BiomÃ©dicos

AplicaciÃ³n de chat basada en el patrÃ³n **RAG (Retrieval Augmented Generation)** que permite a field engineers consultar informaciÃ³n tÃ©cnica de manuales de dispositivos biomÃ©dicos usando Azure AI Search y Azure OpenAI.

## ğŸ“‹ DescripciÃ³n del Proyecto

Esta aplicaciÃ³n estÃ¡ diseÃ±ada para que los **field engineers** puedan hacer preguntas sobre manuales tÃ©cnicos y de usuario de dispositivos biomÃ©dicos durante el mantenimiento de equipos. La aplicaciÃ³n:

1. **Recibe preguntas** del usuario a travÃ©s de una interfaz de chat en Streamlit.
2. **Busca informaciÃ³n relevante** en un Ã­ndice de Azure AI Search que contiene chunks de manuales biomÃ©dicos.
3. **Genera respuestas contextualizadas** usando Azure OpenAI con el contexto recuperado.

## ğŸ—ï¸ Arquitectura

La aplicaciÃ³n utiliza una arquitectura RAG con los siguientes componentes:

- **Frontend**: Streamlit (interfaz de chat interactiva)
- **Motor de bÃºsqueda**: Azure AI Search (Ã­ndice con chunks de manuales biomÃ©dicos)
- **Modelo de lenguaje**: Azure OpenAI (generaciÃ³n de respuestas contextualizadas)
- **PatrÃ³n**: RAG (Retrieval Augmented Generation)

### Flujo de datos:

```
Usuario â†’ Streamlit UI â†’ RAG Pipeline â†’ Azure AI Search (bÃºsqueda)
                                              â†“
                                    Contexto recuperado
                                              â†“
                                    Azure OpenAI (generaciÃ³n)
                                              â†“
                                    Respuesta + Fuentes â†’ Usuario
```

## ğŸ”§ Requisitos Previos

Antes de ejecutar la aplicaciÃ³n, necesitas:

1. **Cuenta de Azure** con acceso a:
   - Azure AI Search (servicio creado)
   - Azure OpenAI (recurso con deployment de modelo de chat, por ejemplo GPT-4 o GPT-3.5-turbo)

2. **Ãndice de Azure AI Search**:
   - Nombre del Ã­ndice: **biomed-manuals-demo-index**
   - El Ã­ndice debe estar creado y poblado con chunks de manuales biomÃ©dicos (PDFs procesados)
   - Los manuales deben estar subidos a Azure Blob Storage y procesados mediante un indexer o el wizard de "Import Data" en Azure Portal
   - Campos del Ã­ndice que usa la aplicaciÃ³n:
     - `content` (String, searchable): Texto de los manuales
     - `metadata_storage_name` (String, filterable, sortable, facetable): Nombre del archivo PDF (mostrado como "source" en la UI)
     - `metadata_storage_path` (String, key): Clave interna del documento

3. **Python 3.x** instalado (recomendado 3.8+)

4. **Variables de entorno** configuradas (ver secciÃ³n de configuraciÃ³n)

## ğŸ“¦ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone <url-del-repositorio>
cd azure-rag-chat
```

### 2. Crear y activar entorno virtual

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

**Linux/Mac:**
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar variables de entorno

Crea un archivo `.env` en la raÃ­z del proyecto basÃ¡ndote en `.env.example`:

```bash
cp .env.example .env
```

Edita el archivo `.env` y completa con tus credenciales de Azure:

```env
# Azure AI Search Configuration
AZURE_SEARCH_ENDPOINT="https://<tu-servicio-search>.search.windows.net"
AZURE_SEARCH_INDEX="biomed-manuals-demo-index"
AZURE_SEARCH_API_KEY="<tu-api-key-search>"

# Azure OpenAI Configuration
AZURE_OPENAI_ENDPOINT="https://<tu-recurso-openai>.openai.azure.com"
AZURE_OPENAI_API_KEY="<tu-api-key-openai>"
AZURE_OPENAI_DEPLOYMENT="<nombre-del-deployment-del-modelo>"

# Streamlit Configuration (opcional)
STREAMLIT_SERVER_PORT="8501"
```

## ğŸš€ Ejecutar la AplicaciÃ³n

Una vez configurado todo, ejecuta:

```bash
streamlit run app/main.py
```

La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en tu navegador en `http://localhost:8501`.

## ğŸ“ Estructura del Proyecto

```
azure-rag-chat/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # AplicaciÃ³n principal de Streamlit
â”‚   â”œâ”€â”€ config.py                  # GestiÃ³n de configuraciÃ³n y variables de entorno
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ azure_search_client.py # Cliente para Azure AI Search
â”‚       â”œâ”€â”€ azure_openai_client.py # Cliente para Azure OpenAI
â”‚       â””â”€â”€ rag_pipeline.py        # Pipeline RAG que orquesta todo
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ search-index-demo.json          # Esquema simplificado de Ã­ndice (demo)
â”‚   â””â”€â”€ search-index-prod-example.json  # Esquema completo para producciÃ³n
â”œâ”€â”€ .env.example                  # Plantilla de variables de entorno
â”œâ”€â”€ requirements.txt              # Dependencias del proyecto
â””â”€â”€ README.md                     # Este archivo
```

## ğŸ“Š Esquema del Ãndice

### Ãndice Real en Azure (`biomed-manuals-demo-index`)

La aplicaciÃ³n estÃ¡ configurada para trabajar con el Ã­ndice **biomed-manuals-demo-index** que debe estar creado en Azure AI Search. Este Ã­ndice utiliza el siguiente esquema:

**Campos principales que usa la aplicaciÃ³n:**
- `content` (String, searchable, retrievable): Texto extraÃ­do de los chunks de los manuales biomÃ©dicos. Este es el campo principal sobre el que se realiza la bÃºsqueda textual.
- `metadata_storage_name` (String, filterable, sortable, facetable, retrievable): Nombre del archivo PDF de origen. La aplicaciÃ³n lo mapea internamente como "source" para mostrarlo en la interfaz.
- `metadata_storage_path` (String, key, retrievable): Ruta de almacenamiento del documento. Este campo es la clave (key) del Ã­ndice.

**Notas:**
- El Ã­ndice no incluye campos como `id`, `source` directo, `pageNumber`, `contentVector` ni configuraciÃ³n de bÃºsqueda vectorial.
- La aplicaciÃ³n realiza bÃºsqueda textual estÃ¡ndar sobre el campo `content`.
- Los archivos JSON en `docs/` (`search-index-demo.json` y `search-index-prod-example.json`) fueron diseÃ±os iniciales de ejemplo, pero la implementaciÃ³n actual estÃ¡ adaptada al esquema real del Ã­ndice creado en Azure Portal.

## ğŸ¯ Uso de la AplicaciÃ³n

1. **Abre la aplicaciÃ³n** en tu navegador (se abre automÃ¡ticamente al ejecutar Streamlit).

2. **Ajusta parÃ¡metros** en la barra lateral (opcional):
   - `top_k`: NÃºmero de documentos a recuperar (1-10)
   - `temperature`: Temperatura del modelo (0.0-1.0)

3. **Escribe tu pregunta** en el campo de chat. Ejemplos:
   - "Â¿CÃ³mo calibro el sensor de oxÃ­geno del modelo X?"
   - "Â¿CuÃ¡l es el procedimiento de mantenimiento preventivo?"
   - "Â¿QuÃ© cÃ³digo de error significa E-123?"
   - "Â¿CÃ³mo cambio el filtro del dispositivo Y?"

4. **Revisa la respuesta** y las fuentes utilizadas (nombre del PDF y pÃ¡gina).

5. **ContinÃºa la conversaciÃ³n** haciendo mÃ¡s preguntas.

6. **Limpia la conversaciÃ³n** usando el botÃ³n en la barra lateral cuando quieras empezar de nuevo.

## ğŸ” CaracterÃ­sticas

- âœ… Interfaz de chat intuitiva con Streamlit
- âœ… BÃºsqueda semÃ¡ntica en manuales biomÃ©dicos
- âœ… GeneraciÃ³n de respuestas contextualizadas
- âœ… VisualizaciÃ³n de fuentes (PDF y pÃ¡gina)
- âœ… ParÃ¡metros ajustables (top_k, temperature)
- âœ… Manejo de errores bÃ¡sico
- âœ… Historial de conversaciÃ³n

## ğŸš§ Mejoras Futuras

Algunas mejoras que se podrÃ­an implementar:

- **Carga de datos desde cÃ³digo**: Script para subir y procesar PDFs automÃ¡ticamente al Ã­ndice
- **Soporte multiidioma**: DetecciÃ³n de idioma y respuestas en mÃºltiples idiomas
- **Filtros avanzados**: Filtrar por modelo, fabricante, tipo de manual desde la UI
- **AutenticaciÃ³n de usuarios**: Sistema de login para control de acceso
- **Logging y trazabilidad**: Registro de preguntas, respuestas y mÃ©tricas de uso
- **BÃºsqueda hÃ­brida mejorada**: IntegraciÃ³n completa de bÃºsqueda vectorial + texto
- **Streaming de respuestas**: Mostrar la respuesta mientras se genera (mejor UX)
- **ExportaciÃ³n de conversaciones**: Guardar historiales de chat en PDF o texto

## ğŸ“ Notas TÃ©cnicas

- La aplicaciÃ³n usa **bÃºsqueda por texto** por defecto. El cÃ³digo estÃ¡ preparado para usar bÃºsqueda vectorial si proporcionas embeddings.
- El modelo de Azure OpenAI debe ser un modelo de **chat** (por ejemplo, GPT-4, GPT-3.5-turbo).
- La versiÃ³n de la API de Azure OpenAI usada es `2024-02-15-preview` (ajustable en `azure_openai_client.py`).
- Los chunks de los manuales deben estar previamente indexados en Azure AI Search.

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor, abre un issue o pull request si tienes sugerencias o mejoras.

## ğŸ“„ Licencia

Este proyecto es una demo educativa. Ajusta la licencia segÃºn tus necesidades.

---

**Desarrollado con â¤ï¸ para field engineers de dispositivos biomÃ©dicos**

